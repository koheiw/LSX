% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/textmodel.R
\name{textmodel_lss}
\alias{textmodel_lss}
\alias{textmodel_lss.dfm}
\alias{textmodel_lss.fcm}
\title{A word embeddings-based semisupervised model for document scaling}
\usage{
textmodel_lss(x, ...)

\method{textmodel_lss}{dfm}(
  x,
  seeds,
  terms = NULL,
  k = 300,
  slice = NULL,
  weight = "count",
  cache = FALSE,
  simil_method = "cosine",
  engine = c("RSpectra", "irlba", "rsvd"),
  include_data = FALSE,
  verbose = FALSE,
  ...
)

\method{textmodel_lss}{fcm}(
  x,
  seeds,
  terms = NULL,
  w = 50,
  weight = "count",
  cache = FALSE,
  simil_method = "cosine",
  engine = c("rsparse"),
  verbose = FALSE,
  ...
)
}
\arguments{
\item{x}{a dfm or fcm created by \code{\link[quanteda:dfm]{quanteda::dfm()}} or \code{\link[quanteda:fcm]{quanteda::fcm()}}}

\item{...}{additional argument passed to the SVD engine}

\item{seeds}{a character vector, named numeric vector or dictionary that
contains seed words.}

\item{terms}{words weighted as model terms. All the features of
\code{\link[quanteda:dfm]{quanteda::dfm()}} or \code{\link[quanteda:fcm]{quanteda::fcm()}} will be used if not specified.}

\item{k}{the number of singular values requested to the SVD engine. Only used
when \code{x} is a \code{dfm}.}

\item{slice}{a number or indices of the components of word vectors used to
compute similarity; \code{slice < k} to truncate word vectors; useful for diagnosys
and simulation.}

\item{weight}{weighting scheme passed to \code{\link[quanteda:dfm_weight]{quanteda::dfm_weight()}}. Ignored
when \code{engine} is "rsparse".}

\item{cache}{if \code{TRUE}, save retult of SVD for next execution with identical
\code{x} and settings.}

\item{simil_method}{specifies method to compute similarity between features.
The value is passed to \code{\link[quanteda:textstat_simil]{quanteda::textstat_simil()}}, "cosine" is used
otherwise.}

\item{engine}{choose SVD engine between \code{\link[RSpectra:svds]{RSpectra::svds()}}, \code{\link[irlba:irlba]{irlba::irlba()}},
and \code{\link[rsparse:GloVe]{rsparse::GloVe()}}.}

\item{include_data}{if \code{TRUE}, fitted model include the dfm supplied as \code{x}.}

\item{verbose}{show messages if \code{TRUE}.}

\item{w}{the size of word vectors. Only used when \code{x} is a \code{fcm}}
}
\description{
A word embeddings-based semisupervised model for document scaling
}
\examples{
\dontrun{
require(quanteda)

# Available at https://bit.ly/2GZwLcN
corp <- readRDS("data_corpus_guardian2016-10k.rds")

toks <- corpus_reshape(corp, "sentences") \%>\%
        tokens(remove_punct = TRUE) \%>\%
        tokens_remove(stopwords("en")) \%>\%
        tokens_select("^[\\\\p{L}]+$", valuetype = "regex", padding = TRUE)
dfmt <- dfm(toks) \%>\%
        dfm_trim(min_termfreq = 10)

# SVD
svd <- textmodel_lss(dfmt, seedwords("pos-neg"))
summary(lss)

# sentiment model on economy
eco <- head(char_keyness(toks, 'econom*'), 500)
svd_eco <- textmodel_lss(dfmt, seedwords('pos-neg'), terms = eco)

# sentiment model on politics
pol <- head(char_keyness(toks, 'politi*'), 500)
svd_pol <- textmodel_lss(dfmt, seedwords('pos-neg'), terms = pol)

# GloVe
fcmt  <- fcm(toks, context = "window", count = "weighted", weights = 1 / (1:5), tri = TRUE)
glov <- textmodel_lss(fcmt, seedwords('pos-neg'))
}

}
\references{
Watanabe, Kohei. "Measuring News Bias: Russia's Official News
Agency ITAR-TASS' Coverage of the Ukraine Crisis." European Journal of
Communication 32, no. 3 (March 20, 2017): 224â€“41.
https://doi.org/10.1177/0267323117695735.
}
